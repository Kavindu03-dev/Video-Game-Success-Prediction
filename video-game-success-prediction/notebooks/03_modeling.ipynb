{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2415f490",
   "metadata": {},
   "source": [
    "# 03 - Modeling\n",
    "Train and evaluate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafd6900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for modeling\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# Make project src importable\n",
    "project_root = Path('..').resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from src.preprocessing import clean_dataset, add_hit_label, encode_categoricals\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cac526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_path = Path('..') / 'data' / 'raw' / 'vg_sales_2024.csv'\n",
    "df = pd.read_csv(raw_path)\n",
    "\n",
    "# Clean + label + encode\n",
    "df = clean_dataset(df)\n",
    "df = add_hit_label(df, sales_col='total_sales', threshold=1.0, label_col='Hit')\n",
    "\n",
    "# Choose features: numeric + encoded categoricals\n",
    "feat_df = encode_categoricals(df, columns=(\"genre\", \"platform\", \"publisher\"), drop_first=True)\n",
    "\n",
    "# Separate X, y\n",
    "y = feat_df['Hit']\n",
    "X = feat_df.drop(columns=['Hit'])\n",
    "\n",
    "# Keep only numeric features for models that expect numeric input\n",
    "X = X.select_dtypes(include=['number']).copy()\n",
    "\n",
    "print(f\"X shape: {X.shape}, y positive rate: {y.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5dc22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split with stratification on Hit\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Train size: {X_train.shape[0]}, Test size: {X_test.shape[0]}, \"\n",
    "    f\"Pos rate (train/test): {y_train.mean():.3f}/{y_test.mean():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f3e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression baseline\n",
    "log_reg = LogisticRegression(max_iter=2000, n_jobs=None)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "pred_lr = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression - Classification Report:\\n\")\n",
    "from sklearn.metrics import classification_report as cr\n",
    "print(cr(y_test, pred_lr, digits=3))\n",
    "\n",
    "metrics_lr = {\n",
    "    'accuracy': accuracy_score(y_test, pred_lr),\n",
    "    'precision': precision_score(y_test, pred_lr, zero_division=0),\n",
    "    'recall': recall_score(y_test, pred_lr, zero_division=0),\n",
    "    'f1': f1_score(y_test, pred_lr, zero_division=0),\n",
    "}\n",
    "metrics_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb47867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest classifier\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest - Metrics:\\n\")\n",
    "metrics_rf = {\n",
    "    'accuracy': accuracy_score(y_test, pred_rf),\n",
    "    'precision': precision_score(y_test, pred_rf, zero_division=0),\n",
    "    'recall': recall_score(y_test, pred_rf, zero_division=0),\n",
    "    'f1': f1_score(y_test, pred_rf, zero_division=0),\n",
    "}\n",
    "metrics_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeabee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Logistic Regression vs Random Forest\n",
    "comparison = pd.DataFrame([metrics_lr, metrics_rf], index=[\"LogReg\", \"RandForest\"]) \n",
    "print(comparison)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da604cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for Random Forest\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "cv_results = cross_validate(rf, X, y, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
    "\n",
    "cv_summary = pd.DataFrame({k: v for k, v in cv_results.items() if k.startswith('test_')})\n",
    "cv_summary.mean().to_frame('mean').join(cv_summary.std().to_frame('std'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02691ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance plot for Random Forest\n",
    "import numpy as np\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feat_names = X.columns.values\n",
    "\n",
    "top_n = 20\n",
    "sel = indices[:top_n]\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.barplot(x=importances[sel], y=feat_names[sel], palette=\"mako\")\n",
    "plt.title(f\"Random Forest Feature Importance (Top {top_n})\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c58bab9",
   "metadata": {},
   "source": [
    "## SHAP Explainability\n",
    "\n",
    "Compute SHAP values for the Random Forest classifier to understand feature impact on the Hit prediction. We focus on the probability of the positive class (Hit = 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c0dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "# Use a TreeExplainer for RandomForestClassifier\n",
    "explainer = shap.TreeExplainer(rf, feature_names=X.columns)\n",
    "\n",
    "# SHAP values for the test set; for classifiers, shap_values is a list per class\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Determine positive class index (usually 1 for binary classification)\n",
    "pos_class_idx = 1 if len(shap_values) > 1 else 0\n",
    "\n",
    "# Summary plot (beeswarm) for positive class\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values[pos_class_idx], X_test, feature_names=X.columns, show=False)\n",
    "plt.title(\"SHAP Summary Plot (Hit=1)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
