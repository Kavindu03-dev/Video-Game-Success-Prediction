{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56360f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "\taccuracy_score,\n",
    "\tclassification_report,\n",
    "\tf1_score,\n",
    "\tprecision_score,\n",
    "\trecall_score,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from src.preprocessing import clean_dataset, add_hit_label\n",
    "\n",
    "\n",
    "def load_data(csv_path: Path) -> pd.DataFrame:\n",
    "\tdf = pd.read_csv(csv_path)\n",
    "\tdf = clean_dataset(df)  # converts release_date -> year in same column if present\n",
    "\t# Standardize a 'release_year' feature\n",
    "\tif 'release_year' not in df.columns:\n",
    "\t\tif 'release_date' in df.columns:\n",
    "\t\t\tdf['release_year'] = df['release_date']\n",
    "\t\telse:\n",
    "\t\t\tdf['release_year'] = pd.NA\n",
    "\n",
    "\t# Create target label\n",
    "\tdf = add_hit_label(df, sales_col='total_sales', threshold=1.0, label_col='Hit')\n",
    "\treturn df\n",
    "\n",
    "\n",
    "def build_pipeline(categorical: list[str], numeric: list[str]) -> Pipeline:\n",
    "\tpre = ColumnTransformer(\n",
    "\t\ttransformers=[\n",
    "\t\t\t(\n",
    "\t\t\t\t'cat',\n",
    "\t\t\t\tOneHotEncoder(handle_unknown='ignore', sparse_output=False),\n",
    "\t\t\t\tcategorical,\n",
    "\t\t\t),\n",
    "\t\t\t# numeric passthrough (RF doesn't require scaling)\n",
    "\t\t\t('num', 'passthrough', numeric),\n",
    "\t\t],\n",
    "\t\tremainder='drop',\n",
    "\t\tverbose_feature_names_out=False,\n",
    "\t)\n",
    "\n",
    "\tclf = RandomForestClassifier(\n",
    "\t\tn_estimators=300,\n",
    "\t\trandom_state=42,\n",
    "\t\tn_jobs=-1,\n",
    "\t)\n",
    "\n",
    "\tpipe = Pipeline(steps=[('pre', pre), ('clf', clf)])\n",
    "\treturn pipe\n",
    "\n",
    "\n",
    "def train_and_evaluate(df: pd.DataFrame) -> Tuple[Pipeline, dict]:\n",
    "\tfeature_cols_cat = ['genre', 'platform', 'publisher']\n",
    "\tfeature_cols_num = ['critic_score', 'release_year']\n",
    "\n",
    "\t# Ensure these columns exist\n",
    "\tfor col in feature_cols_cat + feature_cols_num + ['Hit']:\n",
    "\t\tif col not in df.columns:\n",
    "\t\t\tdf[col] = pd.NA\n",
    "\n",
    "\tX = df[feature_cols_cat + feature_cols_num].copy()\n",
    "\ty = df['Hit'].astype('Int64').fillna(0).astype(int)\n",
    "\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(\n",
    "\t\tX, y, test_size=0.2, random_state=42, stratify=y\n",
    "\t)\n",
    "\n",
    "\t# Build pipeline and fit\n",
    "\tpipe = build_pipeline(feature_cols_cat, feature_cols_num)\n",
    "\tpipe.fit(X_train, y_train)\n",
    "\n",
    "\t# Evaluate RF\n",
    "\ty_pred = pipe.predict(X_test)\n",
    "\tmetrics = {\n",
    "\t\t'accuracy': accuracy_score(y_test, y_pred),\n",
    "\t\t'precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "\t\t'recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "\t\t'f1': f1_score(y_test, y_pred, zero_division=0),\n",
    "\t\t'report': classification_report(y_test, y_pred, digits=3),\n",
    "\t}\n",
    "\n",
    "\t# Optional cross-validation summary\n",
    "\tcv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\tscoring = {'accuracy': 'accuracy', 'precision': 'precision', 'recall': 'recall', 'f1': 'f1'}\n",
    "\tcv_res = cross_validate(pipe, X, y, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
    "\tmetrics['cv_mean'] = {k: float(cv_res[f'test_{k}'].mean()) for k in scoring}\n",
    "\tmetrics['cv_std'] = {k: float(cv_res[f'test_{k}'].std()) for k in scoring}\n",
    "\n",
    "\treturn pipe, metrics\n",
    "\n",
    "\n",
    "def save_model(model: Pipeline, path: Path) -> None:\n",
    "\twith open(path, 'wb') as f:\n",
    "\t\tpickle.dump(model, f)\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "\tproject_root = Path(__file__).resolve().parents[1]\n",
    "\t# Prefer data/vg_sales_2024.csv, fallback to data/raw/vg_sales_2024.csv\n",
    "\tdata_path = project_root / 'data' / 'vg_sales_2024.csv'\n",
    "\tif not data_path.exists():\n",
    "\t\tdata_path = project_root / 'data' / 'raw' / 'vg_sales_2024.csv'\n",
    "\tmodel_path = project_root / 'model.pkl'\n",
    "\n",
    "\tif not data_path.exists():\n",
    "\t\traise FileNotFoundError(f\"Dataset not found at {data_path}. Please place vg_sales_2024.csv there.\")\n",
    "\n",
    "\tprint(\"Loading and cleaning data...\")\n",
    "\tdf = load_data(data_path)\n",
    "\tprint(f\"Samples: {len(df)}, Hit rate: {df['Hit'].mean():.3f}\")\n",
    "\n",
    "\tprint(\"Training model...\")\n",
    "\tmodel, metrics = train_and_evaluate(df)\n",
    "\tprint(\"\\nEvaluation (holdout):\")\n",
    "\tprint(metrics['report'])\n",
    "\tprint(\"CV means:\", metrics['cv_mean'])\n",
    "\tprint(\"CV stds:\", metrics['cv_std'])\n",
    "\n",
    "\tprint(f\"Saving model to {model_path} ...\")\n",
    "\tsave_model(model, model_path)\n",
    "\tprint(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
